## 概述

```bash
yum install sysstat

uptime
dmesg | tail
vmstat 1
mpstat -P ALL 1
pidstat 1
iostat -xz 1
free -m
sar -n DEV 1
sar -n TCP,ETCP 1
top
```

## uptime

````bash
[root@localhost ~]# uptime
 17:06:30 up  8:22,  1 user,  load average: 0.00, 0.01, 0.05
````

这是一个快速展示系统平均负载的方法，这也指出了等待运行进程的数量。在 Linux 系统中，这些数字包括等待 CPU 运行的进程数，也包括了被不可中断 I/O（通常是磁盘  I/O）阻塞的进程。这给出了资源负载的很直接的展示，可以在没有其它工具的帮助下更好的理解这些数据。它是唯一快捷的查看系统负载的方式。

这三个数字是以递减的方式统计了过去 1 分钟，5 分钟和 15  分钟常数的平均数。这三个数字给我们直观展示了随着时间的变化系统负载如何变化。例如，如果你被叫去查看一个有问题的服务器，并且 1  分钟的所代表的值比 15 分钟的值低很多，那么你可能由于太迟登陆机器而错过了问题发生的时间点。

在上面的例子中，平均负载显示是在不断增加的，1 分钟的值是 30，相比 15 分钟的值 19 来说是增加了。这个数字这么大就意味着有事情发生了：可能是 CPU 需求；

## dmesg | tail

这里展示的是最近 10 条系统消息日志，如果系统消息没有就不会展示。主要是看由于性能问题导致的错误。上面这个例子中包含了杀死 OOM 问题的进程，丢弃 TCP 请求的问题。

## vmstat

````bash
[root@localhost ~]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 259464   2108 1292392    0    0     6    27   52  119  0  0 100  0  0
 0  0      0 259472   2108 1292424    0    0     0     0  115  266  0  1 100  0  0
 0  0      0 259472   2108 1292424    0    0     0     0  104  255  0  0 100  0  0
 0  0      0 259472   2108 1292424    0    0     0     0  114  267  0  0 100  0  0
 0  0      0 259472   2108 1292424    0    0     0     0  100  244  0  1 100  0  0
````

vmstat 使用参数 1 来运行的时候，是每 1 秒打印一条统计信息。在这个版本的 vmstat 中，输出的第一行展示的是自从启动后的平均值，而不是前一秒的统计。所以现在，可以跳过第一行，除非你要看一下抬头的字段含义。

**每列含义说明：**

1. r: CPU 上的等待运行的可运行进程数。这个指标提供了判断 CPU 饱和度的数据，因为它不包含 I/O 等待的进程。可解释为：“r” 的值比 CPU 数大的时候就是饱和的。
2. free：空闲内存，单位是 k。如果这个数比较大，就说明你还有充足的空闲内存。“free -m” 和下面第 7 个命令，可以更详细的分析空闲内存的状态。
3. si，so：交换进来和交换出去的数据量，如果这两个值为非 0 值，那么就说明没有内存了。
4. us，sy，id，wa，st：这些是 CPU 时间的分解，是所有 CPU 的平均值。它们是用户时间，系统时间（内核），空闲，等待 I/O 时间，和被偷的时间（这里主要指其它的客户，或者使用 Xen，这些客户有自己独立的操作域）。

CPU 时间的分解可以帮助确定 CPU 是不是非常忙（通过用户时间和系统时间累加判断）。持续的 I/O 等待则表明磁盘是瓶颈。这种情况下 CPU  是比较空闲的，因为任务都由于等待磁盘 I/O 而被阻塞。你可以把等待 I/O 看作是另外一种形式的 CPU  空闲，而这个命令给了为什么它们空闲的线索。

系统时间对于 I/O 处理来说是必须的。比较高的平均系统时间消耗，比如超过了 20%，就有必要进一步探索分析了：也有可能是内核处理 I/O 效率不够高导致。

在上面的例子中，CPU 时间几乎都是用户级别的，说明这是一个应用级别的使用情况。如果 CPU 的使用率平均都超过了 90%。这不一定问题；可以使用 “r” 列来检查使用饱和度。

## mpstat -P ALL

````bash
[root@localhost ~]# mpstat -P ALL 1
Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 	06/11/2020 	_x86_64_	(2 CPU)

05:21:31 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:21:32 PM  all    0.00    0.00    0.50    0.00    0.00    0.00    0.00    0.00    0.00   99.50
05:21:32 PM    0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:21:32 PM    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00

05:21:32 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:21:33 PM  all    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:21:33 PM    0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:21:33 PM    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00

05:21:33 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:21:34 PM  all    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:21:34 PM    0    0.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:21:34 PM    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
````

这个命令分打印各个 CPU 的时间统计，可以看出整体 CPU 的使用是不是均衡的。有一个使用率明显较高的 CPU 就可以明显看出来这是一个单线程应用。

## pidstat

````bash
[root@localhost ~]# pidstat 1
Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 	06/11/2020 	_x86_64_	(2 CPU)

05:22:55 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
05:22:56 PM     0      1117    0.00    0.98    0.00    0.98     0  containerd
05:22:56 PM     0     14937    0.00    0.98    0.00    0.98     1  pidstat

05:22:56 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
05:22:57 PM     0     14937    1.00    2.00    0.00    3.00     1  pidstat

05:22:57 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
05:22:58 PM     0      1117    0.00    1.00    0.00    1.00     0  containerd
05:22:58 PM     0     14937    0.00    1.00    0.00    1.00     1  pidstat
````

pidstat 命令有点像 top 命令中的为每个 CPU 统计信息功能，但是它是以不断滚动更新的方式打印信息，而不是每次清屏打印。这个对于观察随时间变化的模式很有用，同时把你看到的信息（复制粘贴）记到你的调查记录中。

上面的例子可以看出是 2 个 java 进程在消耗 CPU。`%CPU` 列是所有 CPU 的使用率；1591% 是说明这个 java 进程消耗了几乎 16 个 CPU 核。

## iostat -zx

```bash
Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 	06/11/2020 	_x86_64_	(2 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.10    0.00    0.22    0.01    0.00   99.67

Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
scd0              0.00     0.00    0.00    0.00     0.03     0.00   114.22     0.00    1.22    1.22    0.00   0.89   0.00
sda               0.00     0.08    0.32    0.79    11.94    52.21   115.27     0.00    1.73    0.57    2.20   0.30   0.03
dm-0              0.00     0.00    0.25    0.87    10.92    52.15   112.08     0.00    3.47    0.70    4.28   0.29   0.03
dm-1              0.00     0.00    0.00    0.00     0.07     0.00    50.09     0.00    0.10    0.10    0.00   0.06   0.00
```

这个工具对于理解块设备（比如磁盘）很有用，展示了请求负载和性能数据。具体的数据看下面字段的解释：

1. r/s, w/s, rkB/s, wkB/s：这些表示设备上每秒钟的读写次数和读写的字节数（单位是 k 字节）。这些可以看出设备的负载情况。性能问题可能就是简单的因为大量的文件加载请求。
2. await：I/O 等待的平均时间（单位是毫秒）。这是应用程序所等待的时间，包含了等待队列中的时间和被调度服务的时间。过大的平均等待时间就预示着设备超负荷了或者说设备有问题了。
3. avgqu-sz：设备上请求的平均数。数值大于 1 可能表示设备饱和了（虽然设备通常都是可以支持并行请求的，特别是在背后挂了多个磁盘的虚拟设备）。
4. %util：设备利用率。是使用率的百分数，展示每秒钟设备工作的时间。这个数值大于 60% 则会导致性能很低（可以在 await 中看），当然这也取决于设备特点。这个数值接近 100% 则表示设备饱和了。

如果存储设备是一个逻辑磁盘设备，后面挂载了多个磁盘，那么 100% 的利用率则只是表示有些 I/O 是在 100% 处理，然而后端的磁盘或许远远没有饱和，还可以处理更多的请求。

请记住，磁盘 I/O 性能低不一定是应用程序的问题。许多技术通常都被用来实现异步执行 I/O，所以应用程序不会直接阻塞和承受延时（比如：预读取和写缓冲技术）。

## free -m

```bash
[root@localhost ~]# free -m
              total        used        free      shared  buff/cache   available
Mem:           1819         302         243           9        1273        1334
Swap:          2047           0        2047
```

右面两列展示的是：

1. buffers：用于块设备 I/O 缓冲的缓存。
2. cached：用于文件系统的页缓存。

我们只想检测这些缓存的数值是否接近 0 。不为 0 的可能导致较高的磁盘 I/O（通过 iostat 命令来确认）和较差的性能问题。上面的例子看起来没问题，都还有很多 M 字节。

“-/+ buffers/cache” 这一行提供了对已使用和空闲内存明确的统计。Linux 用空闲内存作为缓存，如果应用程序需要，可以快速拿回去。所以应该包含空闲内存那一列，这里就是这么统计的。甚至有一个网站专门来介绍 Linux 内存消耗的问题：[linuxatemyram](https://www.linuxatemyram.com/)。

如果在 Linux 上使用了 ZFS 文件系统，则可能会更乱，因为当我们在开发一些服务的时候，ZFS 有它自己的文件系统缓存，而这部分内存的消耗是不会在 `free -m` 这个命令中合理的反映的。显示了系统内存不足，但是 ZFS 的这部分缓存是可以被应用程序使用的。

## sar -n DEV

```bash
[root@localhost ~]# sar -n DEV 1
Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 	06/11/2020 	_x86_64_	(2 CPU)

05:30:49 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
05:30:50 PM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00
05:30:50 PM     ens33      0.00      0.00      0.00      0.00      0.00      0.00      0.00
05:30:50 PM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00

05:30:50 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
05:30:51 PM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00
05:30:51 PM     ens33      0.99      0.99      0.06      0.45      0.00      0.00      0.00
05:30:51 PM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00

05:30:51 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
05:30:52 PM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00
05:30:52 PM     ens33      1.00      1.00      0.06      0.46      0.00      0.00      0.00
05:30:52 PM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00
```

使用这个工具是可以检测网络接口的吞吐：rxkB/s 和 txkB/s，作为收发数据负载的度量，也是检测是否达到收发极限。

## sar -n TCP,ETCP

```bash
[root@localhost ~]# sar -n TCP,ETCP 1
Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 	06/11/2020 	_x86_64_	(2 CPU)

05:32:39 PM  active/s passive/s    iseg/s    oseg/s
05:32:40 PM      0.00      0.00      1.00      1.00

05:32:39 PM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
05:32:40 PM      0.00      0.00      0.00      0.00      0.00

05:32:40 PM  active/s passive/s    iseg/s    oseg/s
05:32:41 PM      0.00      0.00      1.00      1.00

05:32:40 PM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
05:32:41 PM      0.00      0.00      0.00      0.00      0.00
```

这是对 TCP 关键指标的统计，它包含了以下内容：

1. active/s：每秒本地发起的 TCP 连接数（例如通过 connect() 发起的连接）。
2. passive/s：每秒远程发起的连接数（例如通过 accept() 接受的连接）。
3. retrans/s：每秒 TCP 重传数。

这种主动和被动统计数通常用作对系统负载的粗略估计：新接受连接数（被动），下游连接数（主动）。可以把主动看作是外部的，被动的是内部，但是这个通常也不是非常准确（例如：当有本地到本地的连接时）。

重传是网络或者服务器有问题的一个信号；可能是一个不可靠的网络（例如：公网），或者可能是因为服务器过载了开始丢包。上面这个例子可以看出是每秒新建一个 TCP 连接。

## top

```bash
[root@localhost ~]# top
top - 17:34:56 up  8:51,  1 user,  load average: 0.00, 0.01, 0.05
Tasks: 106 total,   1 running, 105 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,  0.2 sy,  0.0 ni, 99.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  1863104 total,   249176 free,   310032 used,  1303896 buff/cache
KiB Swap:  2097148 total,  2097148 free,        0 used.  1366140 avail Mem 

   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                                                                    
  1117 root      20   0  508068  40668  13980 S   0.3  2.2   5:17.32 containerd                                                                                                                                                                 
     1 root      20   0  128188   6768   4192 S   0.0  0.4   0:02.82 systemd                                                                                                                                                                    
     2 root      20   0       0      0      0 S   0.0  0.0   0:00.05 kthreadd                                                                                                                                                                   
     3 root      20   0       0      0      0 S   0.0  0.0   1:57.31 kworker/0:0                                                                                                                                                                
     4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H                                                                                                                                                               
     5 root      20   0       0      0      0 S   0.0  0.0   0:08.65 kworker/u256:0                                                                                                                                                             
     6 root      20   0       0      0      0 S   0.0  0.0   0:02.99 ksoftirqd/0  
```

top 命令包含了很多我们前面提到的指标。这个命令可以很容易看出指标的变化表示负载的变化，这个看起来和前面的命令有很大不同。

top 的一个缺陷也比较明显，很难看出变化趋势，其它像 vmstat 和 pidstat  这样的工具就会很清晰，它们是以滚动的方式输出统计信息。所以如果你在看到有问题的信息时没有及时的暂停下来（Ctrl-S 是暂停, Ctrl-Q  是继续），那么这些有用的信息就会被清屏。

## htop

yum install htop

## iotop

yun install iotop

## IPTraf

yum install IPTraf

